# Logtail采集原理 {#concept_bjz_3hp_1fb .concept}

使用Logtail客户端采集服务器日志时，Logtail采集日志的流程为：监听文件、读取文件、处理日志、过滤日志、聚合日志和发送数据6个步骤。

在服务器上安装Logtail客户端，并添加Logtail采集配置之后，Logtail即时开始采集日志到日志服务。Logtail的日志采集流程如下：

1.  [监听文件](#)
2.  [读取文件](#)
3.  [处理日志](#)
4.  [过滤日志](#)
5.  [聚合日志](#)
6.  [发送日志](#)

**说明：** 将Logtail采集配置应用到机器组之后，机器组中服务器上没有发生修改事件的日志文件会被判定为历史文件。Logtail在正常运行模式中不支持采集历史文件，若您需要采集历史日志，请参考[导入历史日志文件](cn.zh-CN/用户指南/Logtail采集/文本日志/导入历史日志文件.md)。

## 监听文件 {#section_u2b_x5s_cfb .section}

在服务器上安装Logtail客户端，并根据数据源添加Logtail采集配置之后，Logtail采集配置从服务端实时下发到Logtail。Logtail根据采集配置开始监听文件。

1.  Logtail根据配置的日志路径和最大监控目录深度逐层扫描目录下符合指定文件名规则的日志目录和文件。

    为保证日志采集时效性以及稳定性，Logtail会对采集目录注册事件监听（Linux下[Inotify](http://man7.org/linux/man-pages/man7/inotify.7.html)、Windows下使用[ReadDirectoryChangesW](https://docs.microsoft.com/zh-cn/windows/desktop/api/winbase/nf-winbase-readdirectorychangesw)）以及定期轮询。

2.  Logtail如果监听到指定目录下符合规则的日志文件在应用配置之后没有修改过，则不会采集；如果有日志文件产生了修改事件，会触发采集流程，Logtail开始读取文件。

## 读取文件 {#section_u34_x5s_cfb .section}

确定日志文件有更新后，Logtail开始读取文件。

1.  若该文件首次读取，会检查文件大小。
    -   如果文件小于1 MB，则从文件内容起始位置开启读取。
    -   如果文件大于1 MB，则从文件末尾1 MB处开始读取。
2.  如果该文件曾被Logtail读取过，则从上次读取的Checkpoint处继续读取。
3.  读取文件时，每次最多可以读取512KB，因此每条日志请控制在512KB以内，否则无法正常读取。

## 处理日志 {#section_f41_y5s_cfb .section}

logtail读取日志后，对日志内容进行分行、解析，并确认日志时间字段。

1.  **分行**：

    如果Logtail采集配置中指定了**行首正则**，则根据行首配置对Logtail每次读取的日志数据块进行分行，切分成多条日志；如果没有指定，则将一个数据块作为一条日志处理。

2.  **解析**：

    根据Logtail采集配置，对每条日志内容执行对应的解析，例如正则、分隔符、JSON等。

    **说明：** 如果您的正则式较为复杂，可能会导致CPU占用率过高，请使用合理高效的正则表达式。

3.  **解析失败处理**：

    根据Logtail采集配置中是否开启[丢弃解析失败日志](cn.zh-CN/用户指南/Logtail采集/文本日志/采集文本日志.md#table_eq2_ccc_wdb)功能，判断日志解析失败的处理方式。

    -   开启**丢弃解析失败日志**，则直接丢弃该日志，并上报解析失败的报错信息。
    -   关闭 **丢弃解析失败日志**，则上传解析失败的原始日志，其中Key为**raw\_log**、Value为日志内容。
4.  **设置日志时间字段**：

    -   若未配置时间字段，则日志时间为当前解析时间。
    -   若配置了时间字段：
        -   日志记录的时间距离当前时间12小时以内，则从解析的日志字段中提取时间。
        -   日志记录的时间距离当前时间12小时以上，则丢弃该日志并上传错误信息。

## 过滤日志 {#section_k14_y5s_cfb .section}

处理日志后，根据Logtail采集配置中的[过滤器配置](https://www.alibabacloud.com/help/zh/doc-detail/28967.htm)过滤日志。

-   未设置**过滤器配置**：不过滤日志，执行下一个步骤。
-   已设置**过滤器配置**：对每条日志中的所有字段进行遍历并验证。
    -   符合过滤器配置的日志：如果日志中出现了过滤器中配置的所有字段、且所有对应的字段全部符合配置，则采集该条日志。
    -   不符合过滤器配置的日志：不符合过滤器配置的日志不会被采集。

## 聚合日志 {#section_pvz_y5s_cfb .section}

通过过滤器配置过滤日志后，符合配置的日志数据将发往日志服务。为降低网络请求次数，当日志处理、过滤完毕后，会在Logtail内部缓存一段时间，进行聚合打包，再发送到日志服务。

缓存过程中，如果满足以下条件之一，日志将即时打包发送到日志服务。

-   日志聚合时间超过3秒。
-   日志聚合条数超过4096条。
-   日志聚合总大小超过512 KB。

## 发送日志 {#section_rf4_z5s_cfb .section}

Logtail将采集到的日志数据聚合发送到日志服务。设置[启动参数配置](https://www.alibabacloud.com/help/zh/doc-detail/32278.htm)中的参数`max_bytes_per_sec`和`send_request_concurrency`可以调整日志数据的发送速度和最大并发数，Logtail会保证发送速率以及并发不超过配置值。

若数据发送失败，Logtail自动根据错误信息决定重试或放弃发送。

|错误信息|说明|Logtail处理方式|
|:---|:-|:----------|
|401错误|Logtail客户端没有权限采集数据。|直接丢弃日志包。|
|404错误|Logtail采集配置中指定的Project或Logstore不存在。|直接丢弃日志包。|
|403错误|Shard Quota超出限制。|等待3秒后重试。|
|500错误|服务端异常。|等待3秒后重试。|
|网络超时|网络连接错误。|等待3秒后重试。|

